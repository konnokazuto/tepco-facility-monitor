---
description: 
globs: 
alwaysApply: true
---
# 東京電力 屋外常設物管理システム 要件定義

## 1. プロジェクト概要

- 原発再稼働に向けた安全・セキュリティ管理システムの整備
- 人力では限界のある業務をシステム化
- 管理精度の向上と機会損失の回避

## 2. 目的

1. 安全管理の精度向上
    - 抜け漏れのない仕組みの構築
2. 労働コスト削減
    - 生産性の高い業務に集中できる環境整備
3. 稼働の障壁となる要素の削減
    - 規制庁等、外部に隙を見せない環境の構築

## 3. 技術要件

### 3.1 運用条件

- 稼働時期：12月～2月の積雪期間は要検討
- 検知頻度：最低週1回で対象区域全域をカバー
- 運用時間：年間通じて業務時間中に運用

### 3.2 検知要件

- 対象サイズ：基本30cm立方以上の物体
- 対象物：申請・未申請関わらず、屋外の設置物・保管物
- 対象範囲：建屋5-7の設置エリア周辺
- 検知精度：天候や発電所内の条件を踏まえた適切な検知・判別

### 3.3 システム構成

- ドローン：DJI Matrice 350 RTK + Zenmuse P1カメラ
- 画像処理：Pix4D maticソフトウェア
- AI検知：YOLO v8による物体検出
- ワークステーション要件：
    - CPU：AMD Ryzen 9 7950X または同等品
    - GPU：NVIDIA RTX 4080/4090
    - メモリ：128GB
    - ストレージ：SSD 1TB + HDD 2TB

## 4. コスト

### 4.1 導入コスト（約4,030万円）

- 管理システム構築：1,000万円
- AI検知システム構築：600万円
- PoC（AI検証）：900万円
- 開発費用：330万円
- IT機器一式：350万円
- その他（RFID関連、ドローン等）：850万円

### 4.2 年間運用コスト（約2,929万円）

- システム保守運用：100万円
- 機器購入積立：68万円
- RFID関連：55万円
- 人件費：2,406万円
    - 安全総括：週120分×50週
    - セキュリティ部門：週4時間×50週

## 5. 期待される効果

- 安全総括部の労働時間：768時間→75時間（約90%削減）
- セキュリティ部の労働時間：1,888時間→982時間（約48%削減）
- 未申請物の検知精度向上
- 管理工数の大幅削減

## 6. リスクと対策

1. 積雪期の運用
    - 12月～2月の運用方法要検討
2. 死角エリアの存在
    - 建屋5横の排気塔周辺等
    - 複数回の撮影による補完
3. システムの安定性
    - オンプレミス環境での運用
    - データバックアップ体制の構築


# システムの処理フロー

## 1. データの取り込みフェーズ
### 1.1 申請書処理
- ユーザー認証
- 不正検知
- 申請書データのアップロード

### 1.2 ドローン撮影画像
- 撮影画像の取得
- 画像データの一時保存

## 2. データ処理フェーズ
### 2.1 申請情報の抽出・処理
- 申請書（PDF）からのOCR処理
- データ処理・加工・変換
- チャンク化・Embedding処理
- 申請書データベースへの保存

### 2.2 画像の基本処理
1. オリジナル画像化とデータ処理
2. 画像処理①：移動物検知
3. 画像処理②：変更（色彩）検知
4. 画像処理③：分析・除外処理

### 2.3 画像変更・登録処理
1. 設置物の登録
2. 申請情報の集積・適正管理
3. 確認画面との連携

## 3. 分析フェーズ
### 3.1 差分分析処理
1. 画像分析①：ヒートマップ/画像
2. 画像分析②：差分二値化
3. 画像分析③：セマンティックセグメンテーション

## 4. データベース連携
### 4.1 画像データベース
- 処理済み画像の保存
- メタデータ管理
- 差分情報の保存

### 4.2 申請書データベース
- 構造化データの保存
- 申請情報の管理

## 5. AI/LLM連携
- ローカルLLMによる処理
- OpenAIとの連携
- 地図への記載処理
- 突合処理の実行

## 6. クエリ処理
1. クエリ計画の立案
2. クエリの実行
3. 結果の検証

## 7. 設置物確認プロセス
### 7.1 確認処理
- 設置物の認識
- 確認画面での検証

### 7.2 調査・検索
- 申請書検索
- 画像照合
- 結果の確認

## 重要ポイント
- システムは撮影画像と申請書データを取り込み、最終的に突合する仕組みを実装
- 各処理フェーズでの検証と確認を徹底
- データの整合性を常に維持